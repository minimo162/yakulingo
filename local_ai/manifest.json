{
    "generated_at":  "2026-01-29T13:19:43.3005191+09:00",
    "llama_cpp":  {
                      "repo":  "ggerganov/llama.cpp",
                      "release_tag":  "b7867",
                      "asset_name":  "llama-b7867-bin-win-vulkan-x64.zip",
                      "download_url":  "https://github.com/ggml-org/llama.cpp/releases/download/b7867/llama-b7867-bin-win-vulkan-x64.zip",
                      "server_exe_sha256":  "10938E830A5D70DF83862BAABEEFC484C35207DD5472A56BD7BFFE2BBA970719",
                      "variant":  "vulkan"
                  },
    "model":  {
                  "repo":  "mradermacher/translategemma-12b-it-i1-GGUF",
                  "revision":  "main",
                  "file":  "translategemma-12b-it.i1-IQ4_XS.gguf",
                  "download_url":  "https://huggingface.co/mradermacher/translategemma-12b-it-i1-GGUF/resolve/main/translategemma-12b-it.i1-IQ4_XS.gguf",
                  "sha256":  null,
                  "skipped":  false,
                  "source":  {
                                 "kind":  "gguf",
                                 "repo":  "mradermacher/translategemma-12b-it-i1-GGUF",
                                 "revision":  "main",
                                 "file":  "translategemma-12b-it.i1-IQ4_XS.gguf",
                                 "download_url":  "https://huggingface.co/mradermacher/translategemma-12b-it-i1-GGUF/resolve/main/translategemma-12b-it.i1-IQ4_XS.gguf"
                             },
                  "output":  {
                                 "kind":  "gguf",
                                 "path":  "local_ai/models/translategemma-12b-it.i1-IQ4_XS.gguf",
                                 "path_resolved":  "C:\\Users\\Administrator\\Desktop\\yakulingo\\local_ai\\models\\translategemma-12b-it.i1-IQ4_XS.gguf",
                                 "sha256":  null
                             }
              }
}
