{
    "generated_at":  "2026-01-10T11:09:19.4336257+09:00",
    "llama_cpp":  {
                      "repo":  "ggerganov/llama.cpp",
                      "release_tag":  "b7689",
                      "asset_name":  "llama-b7689-bin-win-cpu-x64.zip",
                      "download_url":  "https://github.com/ggml-org/llama.cpp/releases/download/b7689/llama-b7689-bin-win-cpu-x64.zip",
                      "server_exe_sha256":  "73256B168BE1E06FE4BF2BA791247E7E3CEACE67F912767774EB8F466327C27A"
                  },
    "model":  {
                  "repo":  "unsloth/GLM-4.6V-Flash-GGUF",
                  "file":  "GLM-4.6V-Flash-IQ4_XS.gguf",
                  "download_url":  "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-IQ4_XS.gguf",
                  "sha256":  "23ea7196ed6f595c44591266a1b4b90d56db5a66c5223d49a41a587b81ace35d",
                  "skipped":  false
              }
}
