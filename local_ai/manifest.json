{
    "generated_at":  "2026-01-11T17:25:50.2088669+09:00",
    "llama_cpp":  {
                      "repo":  "ggerganov/llama.cpp",
                      "release_tag":  "b7689",
                      "asset_name":  "llama-b7689-bin-win-cpu-x64.zip",
                      "download_url":  "https://github.com/ggml-org/llama.cpp/releases/download/b7689/llama-b7689-bin-win-cpu-x64.zip",
                      "server_exe_sha256":  "73256B168BE1E06FE4BF2BA791247E7E3CEACE67F912767774EB8F466327C27A"
                  },
    "model":  {
                  "repo":  "dahara1/shisa-v2.1-llama3.2-3b-UD-japanese-imatrix",
                  "file":  "Llama-3.2-3B-Instruct-UD-Q4_K_XL.gguf",
                  "download_url":  "https://huggingface.co/dahara1/shisa-v2.1-llama3.2-3b-UD-japanese-imatrix/resolve/main/Llama-3.2-3B-Instruct-UD-Q4_K_XL.gguf",
                  "sha256":  null,
                  "skipped":  false
              }
}
