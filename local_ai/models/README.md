# local_ai/models

YakuLingo のローカルAI（llama.cpp）で使用するモデル関連ファイルを配置します。

## 既定モデル（固定）

- Upstream: `mradermacher/translategemma-12b-it-i1-GGUF`
- File: `translategemma-12b-it.i1-IQ4_XS.gguf`

## 補足

- `packaging/install_local_ai.ps1` を実行すると、上流の `LICENSE` / `README.md` がこのフォルダにダウンロードされ、内容が上書きされる場合があります。
