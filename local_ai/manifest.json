{
    "generated_at":  "2026-01-29T06:54:58.7522831+09:00",
    "llama_cpp":  {
                      "repo":  "ggerganov/llama.cpp",
                      "release_tag":  "b7865",
                      "asset_name":  "llama-b7865-bin-win-vulkan-x64.zip",
                      "download_url":  "https://github.com/ggml-org/llama.cpp/releases/download/b7865/llama-b7865-bin-win-vulkan-x64.zip",
                      "server_exe_sha256":  "D3EE18EE64A72DD22872D308DE789EBAFC90112846454D60973FE96280B4B0E2",
                      "variant":  "vulkan"
                  },
    "model":  {
                  "repo":  "dahara1/shisa-v2.1-qwen3-8b-UD-japanese-imatrix",
                  "revision":  "main",
                  "file":  "shisa-v2.1-qwen3-8B-UD-Q4_K_XL.gguf",
                  "download_url":  "https://huggingface.co/dahara1/shisa-v2.1-qwen3-8b-UD-japanese-imatrix/resolve/main/shisa-v2.1-qwen3-8B-UD-Q4_K_XL.gguf",
                  "sha256":  null,
                  "skipped":  false,
                  "source":  {
                                 "kind":  "gguf",
                                 "repo":  "dahara1/shisa-v2.1-qwen3-8b-UD-japanese-imatrix",
                                 "revision":  "main",
                                 "file":  "shisa-v2.1-qwen3-8B-UD-Q4_K_XL.gguf",
                                 "download_url":  "https://huggingface.co/dahara1/shisa-v2.1-qwen3-8b-UD-japanese-imatrix/resolve/main/shisa-v2.1-qwen3-8B-UD-Q4_K_XL.gguf"
                             },
                  "output":  {
                                 "kind":  "gguf",
                                 "path":  "local_ai/models/shisa-v2.1-qwen3-8B-UD-Q4_K_XL.gguf",
                                 "path_resolved":  "C:\\Users\\Administrator\\Desktop\\yakulingo\\local_ai\\models\\shisa-v2.1-qwen3-8B-UD-Q4_K_XL.gguf",
                                 "sha256":  null
                             }
              }
}
