{
    "generated_at":  "2026-01-10T19:19:48.2941100+09:00",
    "llama_cpp":  {
                      "repo":  "ggerganov/llama.cpp",
                      "release_tag":  "b7689",
                      "asset_name":  "llama-b7689-bin-win-cpu-x64.zip",
                      "download_url":  "https://github.com/ggml-org/llama.cpp/releases/download/b7689/llama-b7689-bin-win-cpu-x64.zip",
                      "server_exe_sha256":  "73256B168BE1E06FE4BF2BA791247E7E3CEACE67F912767774EB8F466327C27A"
                  },
    "model":  {
                  "repo":  "unsloth/GLM-4.6V-Flash-GGUF",
                  "file":  "GLM-4.6V-Flash-IQ4_XS.gguf",
                  "download_url":  "https://huggingface.co/unsloth/GLM-4.6V-Flash-GGUF/resolve/main/GLM-4.6V-Flash-IQ4_XS.gguf",
                  "sha256":  "23EA7196ED6F595C44591266A1B4B90D56DB5A66C5223D49A41A587B81ACE35D",
                  "skipped":  false
              }
}
