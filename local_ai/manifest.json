{
    "generated_at":  "2026-01-27T02:45:53.4721035+09:00",
    "llama_cpp":  {
                      "repo":  "ggerganov/llama.cpp",
                      "release_tag":  "b7819",
                      "asset_name":  "llama-b7819-bin-win-vulkan-x64.zip",
                      "download_url":  "https://github.com/ggml-org/llama.cpp/releases/download/b7819/llama-b7819-bin-win-vulkan-x64.zip",
                      "server_exe_sha256":  "8728F8F9DE2B775666492D6682C86C44957423AE668B360242E303BE4237EF73",
                      "variant":  "vulkan"
                  },
    "model":  {
                  "repo":  "mradermacher/translategemma-4b-it-i1-GGUF",
                  "revision":  "main",
                  "file":  "translategemma-4b-it.i1-Q6_K.gguf",
                  "download_url":  "https://huggingface.co/mradermacher/translategemma-4b-it-i1-GGUF/resolve/main/translategemma-4b-it.i1-Q6_K.gguf",
                  "sha256":  null,
                  "skipped":  false,
                  "source":  {
                                 "kind":  "gguf",
                                 "repo":  "mradermacher/translategemma-4b-it-i1-GGUF",
                                 "revision":  "main",
                                 "file":  "translategemma-4b-it.i1-Q6_K.gguf",
                                 "download_url":  "https://huggingface.co/mradermacher/translategemma-4b-it-i1-GGUF/resolve/main/translategemma-4b-it.i1-Q6_K.gguf"
                             },
                  "output":  {
                                 "kind":  "gguf",
                                 "path":  "local_ai/models/translategemma-4b-it.i1-Q6_K.gguf",
                                 "path_resolved":  "C:\\Users\\Administrator\\Desktop\\yakulingo\\local_ai\\models\\translategemma-4b-it.i1-Q6_K.gguf",
                                 "sha256":  null
                             }
              }
}
