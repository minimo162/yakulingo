{
    "generated_at":  "2026-01-11T16:08:56.9260578+09:00",
    "llama_cpp":  {
                      "repo":  "ggerganov/llama.cpp",
                      "release_tag":  "b7689",
                      "asset_name":  "llama-b7689-bin-win-cpu-x64.zip",
                      "download_url":  "https://github.com/ggml-org/llama.cpp/releases/download/b7689/llama-b7689-bin-win-cpu-x64.zip",
                      "server_exe_sha256":  "73256B168BE1E06FE4BF2BA791247E7E3CEACE67F912767774EB8F466327C27A"
                  },
    "model":  {
                  "repo":  "unsloth/LFM2.5-1.2B-Instruct-GGUF",
                  "file":  "LFM2.5-1.2B-Instruct-UD-Q4_K_XL.gguf",
                  "download_url":  "https://huggingface.co/unsloth/LFM2.5-1.2B-Instruct-GGUF/resolve/main/LFM2.5-1.2B-Instruct-UD-Q4_K_XL.gguf",
                  "sha256":  null,
                  "skipped":  false
              }
}
